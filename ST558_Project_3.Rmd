---
title: "Project 3"
author: "Shyam & Kamlesh"
date: "11/9/2022"
output: github_document
params:
  data_channel: "data_channel_is_tech"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Library  
```{r lib_import, warning=FALSE, message=FALSE}
library(dplyr)
library(readr)
library(ggplot2)
library(tidyr)
library(DT)
```

# Introdcution  
We are living in a digital world where we are more concerned about our digital footprint and people often look toward the like and share they get on a post that they publish online. We have several social media websites and print media to share our articles. Online print media platform like [Mashable](www.mashable.com) publishes thousand of online media everyday and it is important for them get a more user engagement from the the article they post online. In this dataset we are trying to predict the share based on several predictor columns such as text sentiment polarity, rate of negative words, rate of positive words, and many more.
Why this analysis is important ? From this predictive model, Mashable can predict the number of share they can receive based on the type of article they are publishing online.  


# Data
The dataset summarizes a heterogeneous set of features about articles published by in a period of two years.The dataset has 39644 data points and 61 feature columns. The project is aimed to subset the original dataset based on type of data channel (one of the six type) and then to predict the number of shares. For our project we are using *TECH* data channel for training and building a predictive modeling and eventually extending same model to other five data channel. User will have flexibility to choose the type of analysis they want based on their personal choice.  
```{r dataset, warning=FALSE, message=FALSE}
newspopData <- readr::read_csv('OnlineNewsPopularity.csv',
                              locale = locale(encoding = 'latin1'))
# select specified data channel and drop other data channel columns
# this should be replaced by param$data_channel
newspopData <- newspopData %>% 
  filter(data_channel_is_tech == 1)%>%
  select(everything(), -starts_with('data_channel_is_'))

datatable(newspopData)
```  
# Exploratory Data Analysis  
Before starting EDA, target variable need to be normalize as it has high variance.  
```{r eda, warning=FALSE, message=FALSE}
data("newspopData", package = "ggplot2")
newspopData$scaledShare <- scale(newspopData$shares, center = T, scale = T)

#calculating correlation index
corr.index <- round(cor(newspopData$scaledShare, newspopData$n_tokens_content),2)
# scatterplot
gg <- ggplot(newspopData, aes(x= n_tokens_content, y = scaledShare)) +
  geom_point()+
  labs(subtitle = paste('Word Count Vs Number of Share', 'Tech', sep = ' : '), # need to automate this
      y = 'Number of Share (Scaled)',
      x = 'Number of Words in article', 
      title = 'Scatterplot',  # replace this with the main title
      caption = 'Source: News Popularity Dataset') + 
      geom_text(x = 4000, y = 60, size = 4, label = paste0("Correlation coefficient = ", corr.index), color = 'red')
plot(gg)
```  

We can inspect trend of Number of shares (scaled) as a function of Number of words in the article. If the points show an upward trend, then the article with high number of words are shared more. However, if we see a negative trend then we can estimate that with increasing number of words in the article, number of shares decreases. This trend can be investigated further  
```{r}
# table for article published during week or weekend 
df <- newspopData %>%select(starts_with('weekday'), shares)
monCount  <-  sum(df$weekday_is_monday * df$shares)/1e6
tueCount  <- sum(df$weekday_is_tuesday*df$shares)/1e6
wedCount  <- sum(df$weekday_is_wednesday*df$shares)/1e6
thurCount <- sum(df$weekday_is_thursday*df$shares)/1e6
friCount  <- sum(df$weekday_is_friday*df$shares)/1e6
satCount  <- sum(df$weekday_is_saturday*df$shares)/1e6
sunCount  <- sum(df$weekday_is_sunday*df$shares)/1e6

# creating a data frame
df <- data.frame(Day <- c('Monday', 'Tuesday', 
                          'Wednesday', 'Thursday', 
                          'Friday', 'Saturday', 'Sunday'),
                 count <-c(monCount, tueCount, wedCount,  
                           thurCount, friCount,
                           satCount, sunCount ))
# plot
gg <- ggplot(df, aes(x = factor(Day), y = count)) +
  geom_bar(stat = 'identity', width = 0.5, fill = 'tomato3')+
  labs(title = 'Bar Chart',
       subtitle = paste('Number of Shares (Million) Vs Day of Week','data channel is Tech', sep = ' : '), # need to automate this too
       caption = 'Source : News Popularity Dataset',
       y = 'Total Share count in Million',
       x = 'Day of the Week') +
  theme(axis.text.x = element_text(angle = 65, vjust = 0.6))
plot(gg)
```  
This plot is about if the article is published during weekday or weekend. From the ordered bar chart more articles are published in weekdays
```{r, warning=FALSE, message=FALSE}
# trying to make facet plot for images and videos
df <- newspopData%>%select(num_imgs, num_videos, shares)%>%
  pivot_longer(cols = c('num_imgs', 'num_videos', 'shares'),
                         names_to = 'params',
                         values_to = 'count')
df
```

