---
title: "Project 3"
author: "Shyam Gadhwala & Kamlesh Pandey"
output: github_document
params:
  data_channel: "data_channel_is_tech"
---

# Library  
```{r lib_import, warning=FALSE, message=FALSE}
library(dplyr)
library(readr)
library(ggplot2)
library(tidyr)
library(DT)
library(tidyverse)
library(caret)
```

# Introdcution  
We are living in a digital world where people are more concerned about the digital footprint and people often consider the like and shares they get on a post that they publish online as an important metric. We have several social media websites and print media to share our articles. Online print media platform like [Mashable](www.mashable.com) publishes thousand of online media everyday and it is important for them get a more user engagement from the the article they post online. In this dataset we are trying to predict the shares based on several predictor, such as text sentiment polarity, rate of negative words, rate of positive words, and many more.
Why this analysis is important ? From this predictive model, Mashable can predict the number of shares they can receive based on the type of article they are publishing online.  


# Data
The dataset summarizes a heterogeneous set of features about articles published by in a period of two years.The dataset has 39644 data points and 61 feature columns. The project is aimed to subset the original dataset based on type of data channel (one of the six type) and then to predict the number of shares. For our project we are using *TECH* data channel for training and building a predictive modeling and eventually extending same model to other five data channel. User will have flexibility to choose the type of analysis they want based on their personal choice.  
```{r dataset, warning=FALSE, message=FALSE}
newspopData <- read_csv('OnlineNewsPopularity.csv',
                              locale = locale(encoding = 'latin1'))
# select specified data channel and drop other data channel columns
# this should be replaced by param$data_channel
newspopData <- filter(newspopData, newspopData[params$data_channel]== 1)%>%
  select(everything(), -starts_with('data_channel_is_'), -url)


newspopData %>%
  select(everything(), -starts_with('data_channel_is_'))

datatable(newspopData)
```  
# Exploratory Data Analysis  
Before starting EDA, target variable need to be normalize as it has high variance.  
```{r eda, warning=FALSE, message=FALSE}
#data("newspopData", package = "ggplot2")
newspopData$scaledShare <- scale(newspopData$shares, center = T, scale = T)

#calculating correlation index
corr.index <- round(cor(newspopData$scaledShare, newspopData$n_tokens_content),2)
# scatterplot
ggplot(newspopData, aes(x= n_tokens_content, y = scaledShare)) +
  geom_point()+
  labs(subtitle = 'Word Count v/s Number of Shares', # need to automate this
      y = 'Number of Share (Scaled)',
      x = 'Number of Words in article', 
      title = toupper(str_replace_all(params$data_channel, "_", " ")),  # replace this with the main title
      caption = 'Source: News Popularity Dataset') + 
      geom_text(x = 4000, y = 60, size = 4, 
                label = paste0("Correlation coefficient = ", corr.index), color = 'red')

```  

We can inspect trend of Number of shares (scaled) as a function of Number of words in the article. If the points show an upward trend, then the article with high number of words are shared more. However, if we see a negative trend then we can estimate that with increasing number of words in the article, number of shares decreases. This trend can be investigated further with the correlation coefficient.  


```{r, warning=FALSE}
newspopData <- newspopData %>% mutate(day = if_else(weekday_is_monday==   1, "Monday", 
                                            if_else(weekday_is_tuesday==  1, "Tuesday",
                                            if_else(weekday_is_wednesday==1, "Wednesday",
                                            if_else(weekday_is_thursday== 1, "Thursday",
                                            if_else(weekday_is_friday==   1, "Friday",
                                            if_else(weekday_is_saturday== 1,"Saturday",
                                            if_else(weekday_is_sunday==   1, "Sunday", 
                                                    "-"))))))))

newspopData$day <- as_factor(newspopData$day)

```


```{r}

ggplot(newspopData, aes(x = day, y = shares/1000000)) +
  geom_bar(stat = 'identity', width = 0.5, fill = 'tomato3')+
  labs(subtitle = 'Number of Shares (Million) Vs Day of Week', # need to automate this too
       caption = 'Source : News Popularity Dataset',
       y = 'Total Share count in Million',
       x = 'Day of the Week',
       title = toupper(str_replace_all(params$data_channel, "_", " ")),) +
       theme(axis.text.x = element_text(angle = 65, vjust = 0.6)) + 
       theme(plot.caption = element_text(size=9, color="red", face="italic", hjust = 1))

```  
From this bar chart we can visualize the shares trend across the week. The users engagement with the type of data Chanel (tech, entertainment, politics) will be different across the week. Users may be more inclined toward sharing lifestyle and entertainment news during weekend and prefer less to share technology/science related news during same time.

```{r}
pp <- ggplot(newspopData, aes(x = global_rate_positive_words, y = global_sentiment_polarity)) 

pp +  geom_point(aes(col = day, size = shares/1e6)) + 
      geom_smooth(aes(col = day), method = 'lm', se = F) + 
       labs(subtitle = 'Positive Rate VS Sentiment Polarity Plot',
       x = 'Global Positive Word Rate',
       y = 'Global Sentiment Polarity',
       title = toupper(str_replace_all(params$data_channel, "_", " ")),
       caption = "Source : News Popularity Dataset",
       color = 'Days',
       size = 'Shares per Million') + 
       theme(plot.caption = element_text(size=9, color="red", face="italic", hjust = 1))
      

```


```{r}
ggplot(newspopData, aes(x = global_rate_negative_words, y = global_sentiment_polarity)) + 
      geom_point(aes (col = day, size = shares/1e6)) + 
      geom_smooth(aes(col = day), method = 'lm', se = F) + 
  labs(subtitle = 'Positive Rate VS Sentiment Polarity Plot',
       x = 'Global Negative Word Rate',
       y = 'Global Sentiment Polarity',
       title = toupper(str_replace_all(params$data_channel, "_", " ")),
       caption = "Source : News Popularity Dataset",
       color = 'Days',
       size = 'Shares per Million') + 
       theme(plot.caption = element_text(size=9, color="red", face="italic", hjust = 1))
```  

This plot estimates the general sentiments of users based on positive and negative words in the content. As expected, an article with more positive words has a positive sentiment index and more shares.

                                                                        ### Shyam #####
Plotting the number of shares based on the number of images and videos that an article has, based on what day of the week it is:

```{r, warning=FALSE, fig.width=20}

ggplot(newspopData, aes(x=day, y =   shares/1000000)) + 
  geom_bar(aes(fill = as_factor(num_imgs)), stat="identity", position="dodge") + 
  #geom_smooth(aes(col = day), method = 'lm', se = F) +
  #ylim(0, 0.12) +
  labs(subtitle = 'Number of Images in article v/s number of shares',
       x = 'Number of Images',
       y = 'Number of shares (in millions)',
       title = toupper(str_replace_all(params$data_channel, "_", " ")),
       caption = "Source : News Popularity Dataset")

```

```{r, warning=FALSE}
ggplot(newspopData, aes(x =  num_keywords, y =  shares/1000000)) + 
  geom_bar(aes(fill = day), stat="identity") + 
  scale_x_discrete(limits=c(2:10)) +
  labs(subtitle = 'Shares based on number of keywords',
       x = 'Number of Keywords',
       y = 'Shares (in millions)',
       title = toupper(str_replace_all(params$data_channel, "_", " ")),
       caption = "Source : News Popularity Dataset")

```


```{r}

pols = c("Extremely Positive", "Positive", "Negative", "Extremely Negative")

newspopData <- newspopData %>% mutate(title_Sentiment_Class = 
                                        if_else(title_sentiment_polarity > 0.5, pols[1],
                                        if_else(title_sentiment_polarity > 0, pols[2],
                                        if_else(title_sentiment_polarity > -0.5, pols[3], pols[4]))))


newspopData$title_Sentiment_Class <- as_factor(newspopData$title_Sentiment_Class)
```

```{r}
ggplot(newspopData, aes(x=title_Sentiment_Class, y=shares/1000000)) +
  geom_bar(aes(fill = day), stat="identity", position="dodge") +
  labs(subtitle = 'Shares based on title sentiment and day of the week',
       x = 'Title Sentiment Category',
       y = 'Shares (in millions)',
       title = toupper(str_replace_all(params$data_channel, "_", " ")),
       caption = "Source : News Popularity Dataset") +
      geom_text(x = 3, y = 0.6, size = 3, 
                label = paste("Title Sentiment Score range", "Extremely Positive = 0.5 <--> 1", 
                              'Positive = 0 <--> 0.5 ', 
                              'Negative = -0.5 <--> 0', 
                              'Extremely Negative = -1 <--> -0.5', 
                              sep = '\n' ), color = 'black')

```


```{r, fig.width=20}

ggplot(newspopData, aes(x= title_sentiment_polarity)) +
  geom_density(aes(fill=title_Sentiment_Class), alpha = 0.7) +
  facet_grid(. ~day)+
  scale_fill_discrete(name = "Title Sentiment") +
  labs(subtitle = 'Distribution of articles on title sentiment and day of the week',
       x = 'Title Sentiment Polarity',
       y = 'Density',
       title = toupper(str_replace_all(params$data_channel, "_", " ")),
       caption = "Source : News Popularity Dataset")

```


# Modelling  

## Variable Selection  
```{r}
modelLm <- lm(shares ~ . , 
              data = newspopData %>% 
                select(-day, -scaledShare, -title_Sentiment_Class))
pVal <- data.frame(summary(modelLm)$coefficients[,4])
pVal$row_names <- row.names(pVal)
pVal <- pVal %>% filter(pVal[,1] < 0.05)
cols = c()
if (pVal[,2][1] == "(Intercept)"){
  cols = pVal[,2][-1]
}else{
  cols = pVal[,2]
}
cols

```

## Train Test Split  
```{r}
set.seed(42)
index <- sample(1:dim(newspopData)[1], dim(newspopData)[1]*0.7, replace = F)
trainDf <- newspopData[index, ]
testDf  <- newspopData[-index, ]

```


## Forward Stepwise Regression
```{r, warning=FALSE, message=FALSE}

swFroward <- train(shares ~ ., data = trainDf,
                    preProcess = c("center", "scale"),
                    method = "leapForward")


swFrowardPrediction <- predict(swFroward, newdata = testDf)


swForwardRes <- postResample(swFrowardPrediction, obs = testDf$shares)
swForwardRes

```


## Lasso Regression  
```{r}

fitLASSO <- train(shares ~. , data = trainDf %>% select(cols, shares), 
                  method = "lm",
                  preProcess = c("center", "scale"), 
                  trControl = trainControl(method = "cv", number = 3)
                  )
fitLASSO

#coeff <- predict(fitLASSO$finalModel, type = "coef", mode = "fraction",
#s = fitLASSO$bestTune$fraction, testDf)
#print(coeff)

predLASSO <- predict(fitLASSO, newdata = testDf)
lassoRes <- postResample(predLASSO, obs = testDf$shares)
lassoRes
```

## Variable Selection :PCA

```{r}
set.seed(200)
trainIndex <- createDataPartition(newspopData$shares, p = 0.7, list = FALSE)

trainData <- newspopData[trainIndex, ]
testData <- newspopData[-trainIndex, ]

```


```{r}

PCs <- prcomp(trainData %>% select(-shares, -day, -title_Sentiment_Class), center=TRUE, scale=TRUE)
#pca

var = cumsum(PCs$sdev**2/sum(PCs$sdev**2))

show(plot(var, xlab = "Principal Component",
ylab = "Cum. Prop of Variance Explained", ylim = c(0, 1), type = 'b'))

pt <- min(which(var > 0.80))

points(pt, var[pt], col="red", cex=2, pch=20)
text(8, 0.8, col="red", paste0(round(100*var[pt],2), "% variance \nis explained by ", pt, " \nnumber of PC(s)"))
```


```{r}

treeTrainData <- predict(PCs, newdata = trainData %>% select(-shares)) %>% 
  as_tibble() %>% 
  select(PC1:paste0("PC", pt))

treeTrainData$shares <- trainData$shares
treeTrainData
```



## Random Forest
```{r}
set.seed(400)
trctrl <- trainControl(method = "repeatedcv", number = 3)
randomForest <- train(shares ~., data = treeTrainData, 
                      method = "rf",
                      trControl=trctrl,
                      preProcess = c("center", "scale"),
                      tuneGrid = expand.grid(mtry = 1:as.integer(pt/3)))

randomForest


```


```{r}
treeTestData <- predict(PCs, newdata = testData %>% select(-shares)) %>% 
  as_tibble() %>% 
  select(PC1:paste0("PC", pt))

rfPredict <- predict(randomForest, newdata = treeTestData)
randomFRes <- postResample(rfPredict, obs = testData$shares)
randomFRes

```

## Boosted Tree  
```{r}
boostedTree <- train(shares ~., data = trainData, method = "gbm",
                     trControl = trainControl(method = "repeatedcv", number = 3),
                     preProcess = c("center", "scale"),
                     tuneGrid = expand.grid(n.trees = c(25, 50, 100, 150, 200),
                                            interaction.depth = 1:4,
                                            shrinkage = 0.1,
                                            n.minobsinnode = 10),
                     verbose = FALSE)
#boostedTree

# prediction
boostedTPredict <- predict(boostedTree, newdata = testData)
boostedTRes <- postResample(boostedTPredict, obs = testData$shares)

boostedTRes
```