---
title: "Project 3"
author: "Shyam & Kamlesh"
date: "11/9/2022"
output: github_document
params:
  data_channel: "data_channel_is_tech"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Library  
```{r lib_import, warning=FALSE, message=FALSE}
library(dplyr)
library(readr)
library(ggplot2)
library(tidyr)
library(DT)
```

# Introdcution  
We are living in a digital world where we are more concerned about our digital footprint and people often look toward the like and share they get on a post that they publish online. We have several social media websites and print media to share our articles. Online print media platform like [Mashable](www.mashable.com) publishes thousand of online media everyday and it is important for them get a more user engagement from the the article they post online. In this dataset we are trying to predict the share based on several predictor columns such as text sentiment polarity, rate of negative words, rate of positive words, and many more.
Why this analysis is important ? From this predictive model, Mashable can predict the number of share they can receive based on the type of article they are publishing online.  


# Data
The dataset summarizes a heterogeneous set of features about articles published by in a period of two years.The dataset has 39644 data points and 61 feature columns. The project is aimed to subset the original dataset based on type of data channel (one of the six type) and then to predict the number of shares. For our project we are using *TECH* data channel for training and building a predictive modeling and eventually extending same model to other five data channel. User will have flexibility to choose the type of analysis they want based on their personal choice.  
```{r dataset, warning=FALSE, message=FALSE}
newspopData <- readr::read_csv('OnlineNewsPopularity.csv',
                              locale = locale(encoding = 'latin1'))
# select specified data channel and drop other data channel columns
# this should be replaced by param$data_channel
newspopData <- newspopData %>% 
  filter(params$data_channel == 1)%>%
  select(everything(), -starts_with('data_channel_is_'))

datatable(newspopData)
```  
# Exploratory Data Analysis  
Before starting EDA, target variable need to be normalize as it has high variance.  
```{r eda, warning=FALSE, message=FALSE}
data("newspopData", package = "ggplot2")
newspopData$scaledShare <- scale(newspopData$shares, center = T, scale = T)

#calculating correlation index
corr.index <- round(cor(newspopData$scaledShare, newspopData$n_tokens_content),2)
# scatterplot
gg <- ggplot(newspopData, aes(x= n_tokens_content, y = scaledShare)) +
  geom_point()+
  labs(subtitle = paste('NEED TO AUTOMATE', 'Tech', sep = ' : '), # need to automate this
      y = 'Number of Share (Scaled)',
      x = 'Number of Words in article', 
      title = 'Word Count Vs Number of Share',  # replace this with the main title
      caption = 'Source: News Popularity Dataset') + 
      geom_text(x = 4000, y = 60, size = 4, label = paste0("Correlation coefficient = ", corr.index), color = 'red')
plot(gg)
```  

We can inspect trend of Number of shares (scaled) as a function of Number of words in the article. If the points show an upward trend, then the article with high number of words are shared more. However, if we see a negative trend then we can estimate that with increasing number of words in the article, number of shares decreases. This trend can be investigated further with the correlation coefficient.  
```{r}
# table for article published during week or weekend 
df <- newspopData %>%select(starts_with('weekday'), shares)
monCount  <-  sum(df$weekday_is_monday * df$shares)/1e6
tueCount  <- sum(df$weekday_is_tuesday*df$shares)/1e6
wedCount  <- sum(df$weekday_is_wednesday*df$shares)/1e6
thurCount <- sum(df$weekday_is_thursday*df$shares)/1e6
friCount  <- sum(df$weekday_is_friday*df$shares)/1e6
satCount  <- sum(df$weekday_is_saturday*df$shares)/1e6
sunCount  <- sum(df$weekday_is_sunday*df$shares)/1e6

# creating a data frame
df <- data.frame(Day <- c('Monday', 'Tuesday', 
                          'Wednesday', 'Thursday', 
                          'Friday', 'Saturday', 'Sunday'),
                 count <-c(monCount, tueCount, wedCount,  
                           thurCount, friCount,
                           satCount, sunCount ))
# plot
gg <- ggplot(df, aes(x = factor(Day), y = count)) +
  geom_bar(stat = 'identity', width = 0.5, fill = 'tomato3')+
  labs(title = 'Bar Chart',
       subtitle = paste('Number of Shares (Million) Vs Day of Week','data channel is Tech', sep = ' : '), # need to automate this too
       caption = 'Source : News Popularity Dataset',
       y = 'Total Share count in Million',
       x = 'Day of the Week') +
  theme(axis.text.x = element_text(angle = 65, vjust = 0.6))
plot(gg)
```  
From this bar chart we can visualize the shares trend across the week. The users engagement with the type of data Chanel (tech, entertainment, politics) will be different across the week. Users may be more inclined toward sharing lifestyle and entertainment news during weekend and prefer less to share technology/science related news during same time.  
```{r, warning=FALSE, message=FALSE}
# contingency table
df <- newspopData%>%
  select(shares, starts_with('weekday_is'),  global_sentiment_polarity, starts_with('global_rate_'))%>%
  pivot_longer(cols = starts_with('weekday_is_'),
                         names_to = 'Days',
                         values_to = 'count') %>% filter(count == 1) %>% select(everything(), -count)

#trying to rename the days col
#df$days <- apply(as.data.frame(df$Days), MARGIN = 2, FUN = function(x){sub(".*_is_ ", "" , x)})
datatable(df)
```  

```{r}

par(mfrow = c(1,2))
gg <- ggplot(df, aes(x = global_rate_positive_words, y = global_sentiment_polarity)) + 
      geom_point(aes (col = Days, size = shares/1e5)) + 
      geom_smooth(aes(col = Days), method = 'lm', se = F) + 
  labs(subtitle = 'Positive Rate VS Sentiment Polarity Plot',
       x = 'Global Positive Word Rate',
       y = 'Global Sentiment Polarity',
       title = "Needc to automate",
       caption = "Source : News Popularity Dataset")

plot(gg)

gg1<- ggplot(df, aes(x = global_rate_negative_words, y = global_sentiment_polarity)) + 
      geom_point(aes (col = Days, size = shares/1e5)) + 
      geom_smooth(aes(col = Days), method = 'lm', se = F) + 
  labs(subtitle = 'Positive Rate VS Sentiment Polarity Plot',
       x = 'Global Negative Word Rate',
       y = 'Global Sentiment Polarity',
       title = "Needc to automate",
       caption = "Source : News Popularity Dataset")
plot(gg1)

```  

This plot estimates the general sentiments of users based on positive and negative words in the content. As expected, an article with more positive words has a positive sentiment index and more shares.


