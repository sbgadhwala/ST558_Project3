---
title: "Project 3"
author: "Shyam Gadhwala & Kamlesh Pandey"
output: github_document
params:
  data_channel: "data_channel_is_tech"
---

# Library  
```{r lib_import, warning=FALSE, message=FALSE}
library(dplyr)
library(readr)
library(ggplot2)
library(tidyr)
library(DT)
library(tidyverse)
```

# Introdcution  
We are living in a digital world where people are more concerned about the digital footprint and people often consider the like and shares they get on a post that they publish online as an important metric. We have several social media websites and print media to share our articles. Online print media platform like [Mashable](www.mashable.com) publishes thousand of online media everyday and it is important for them get a more user engagement from the the article they post online. In this dataset we are trying to predict the shares based on several predictor, such as text sentiment polarity, rate of negative words, rate of positive words, and many more.
Why this analysis is important ? From this predictive model, Mashable can predict the number of shares they can receive based on the type of article they are publishing online.  


# Data
The dataset summarizes a heterogeneous set of features about articles published by in a period of two years.The dataset has 39644 data points and 61 feature columns. The project is aimed to subset the original dataset based on type of data channel (one of the six type) and then to predict the number of shares. For our project we are using *TECH* data channel for training and building a predictive modeling and eventually extending same model to other five data channel. User will have flexibility to choose the type of analysis they want based on their personal choice.  
```{r dataset, warning=FALSE, message=FALSE}
newspopData <- read_csv('OnlineNewsPopularity.csv',
                              locale = locale(encoding = 'latin1'))
# select specified data channel and drop other data channel columns
# this should be replaced by param$data_channel
newspopData <- newspopData %>% 
  filter(data_channel_is_tech == 1)%>%
  select(everything(), -starts_with('data_channel_is_'), -url)


newspopData %>%
  select(everything(), -starts_with('data_channel_is_'))

datatable(newspopData)
```  
# Exploratory Data Analysis  
Before starting EDA, target variable need to be normalize as it has high variance.  
```{r eda, warning=FALSE, message=FALSE}
#data("newspopData", package = "ggplot2")
newspopData$scaledShare <- scale(newspopData$shares, center = T, scale = T)

#calculating correlation index
corr.index <- round(cor(newspopData$scaledShare, newspopData$n_tokens_content),2)
# scatterplot
ggplot(newspopData, aes(x= n_tokens_content, y = scaledShare)) +
  geom_point()+
  labs(subtitle = paste('NEED TO AUTOMATE', 'Tech', sep = ' : '), # need to automate this
      y = 'Number of Share (Scaled)',
      x = 'Number of Words in article', 
      title = 'Word Count Vs Number of Share',  # replace this with the main title
      caption = 'Source: News Popularity Dataset') + 
      geom_text(x = 4000, y = 60, size = 4, 
                label = paste0("Correlation coefficient = ", corr.index), color = 'red')

```  

We can inspect trend of Number of shares (scaled) as a function of Number of words in the article. If the points show an upward trend, then the article with high number of words are shared more. However, if we see a negative trend then we can estimate that with increasing number of words in the article, number of shares decreases. This trend can be investigated further with the correlation coefficient.  


```{r}
newspopData <- newspopData %>% mutate(day = if_else(weekday_is_monday==1, "Monday", 
                                            if_else(weekday_is_tuesday==1, "Tuesday",
                                            if_else(weekday_is_wednesday==1, "Wednesday",
                                            if_else(weekday_is_thursday==1, "Thursday",
                                            if_else(weekday_is_friday==1, "Friday",
                                            if_else(weekday_is_saturday==1,"Saturday",
                                            if_else(weekday_is_sunday==1, "Sunday", 
                                                    "-"))))))))

newspopData$day <- as_factor(newspopData$day)
```


```{r}

ggplot(newspopData, aes(x = day, y = shares/1000000)) +
  geom_bar(stat = 'identity', width = 0.5, fill = 'tomato3')+
  labs(title = 'Bar Chart',
       subtitle = paste('Number of Shares (Million) Vs Day of Week','data channel is Tech', sep = ' : '), # need to automate this too
       caption = 'Source : News Popularity Dataset',
       y = 'Total Share count in Million',
       x = 'Day of the Week') +
  theme(axis.text.x = element_text(angle = 65, vjust = 0.6))

```  
From this bar chart we can visualize the shares trend across the week. The users engagement with the type of data Chanel (tech, entertainment, politics) will be different across the week. Users may be more inclined toward sharing lifestyle and entertainment news during weekend and prefer less to share technology/science related news during same time.

```{r}
par(mfrow = c(1,2))
gg <- ggplot(newspopData, aes(x = global_rate_positive_words, y = global_sentiment_polarity)) + 
      geom_point(aes (col = day, size = shares/1e5)) + 
      geom_smooth(aes(col = day), method = 'lm', se = F) + 
  labs(subtitle = 'Positive Rate VS Sentiment Polarity Plot',
       x = 'Global Positive Word Rate',
       y = 'Global Sentiment Polarity',
       title = "Needc to automate",
       caption = "Source : News Popularity Dataset")
plot(gg)
gg1<- ggplot(newspopData, aes(x = global_rate_negative_words, y = global_sentiment_polarity)) + 
      geom_point(aes (col = day, size = shares/1e5)) + 
      geom_smooth(aes(col = day), method = 'lm', se = F) + 
  labs(subtitle = 'Positive Rate VS Sentiment Polarity Plot',
       x = 'Global Negative Word Rate',
       y = 'Global Sentiment Polarity',
       title = "Needc to automate",
       caption = "Source : News Popularity Dataset")
plot(gg1)
```  

This plot estimates the general sentiments of users based on positive and negative words in the content. As expected, an article with more positive words has a positive sentiment index and more shares.

### Shyam #####
Plotting the number of shares based on the number of images and videos that an article has, based on what day of the week it is:

```{r}


ggplot(newspopData, aes(x=shares, y =   num_imgs)) + 
  geom_point(aes(col = day)) + 
  geom_smooth(aes(col = day), method = 'lm', se = F) +
  xlim(0, 20000)

ggplot(newspopData, aes(x=shares, y =   num_videos)) + 
  geom_point(aes(col = day))


```


```{r, warning=FALSE}
ggplot(newspopData, aes(x =  num_keywords, y =  shares/1000000)) + 
  geom_bar(aes(fill = day), stat="identity") + 
  scale_x_discrete(limits=c(2:10)) +
  labs(subtitle = 'Shares based on number of keywords',
       x = 'Number of Keywords',
       y = 'Shares (in millions)',
       title = "Need to automate",
       caption = "Source : News Popularity Dataset")

```